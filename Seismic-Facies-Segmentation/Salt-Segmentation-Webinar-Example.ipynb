{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial example is on the application of CNN image segmentation on salt identification. The train and test data were gotten from TGS-Kaggle Salt Identification challenge in 2018: https://www.kaggle.com/c/tgs-salt-identification-challenge/ . A majority of the code in this notebook was extracted from: https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277 by Kjetil Åmdal-Sævik.\n",
    "\n",
    "The train data consist of 4000 (101 by 101) seismic patches and 4000 corresponding masks indicating regions of salt presence or not. The test data consist of 18000 (101 by 101) seismic patches. The aim of the competition was to predict regions of salt or no salt on the test seismic patches.\n",
    "\n",
    "In this example, we will be covering how to use th U-Net model (a popular type of image segmentation model) to identify salt regions from seismic image patches and the following;\n",
    "\n",
    "* Loading the data and preparation\n",
    "* Training the U-Net\n",
    "* Saving the trained model\n",
    "* Prediction\n",
    "* Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries and packages\n",
    "\n",
    "import os, sys, random, warnings\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some example image and mask patches\n",
    "\n",
    "ids= ['0a1742c740','5b7c160d0d','6c40978ddf','7dfdf6eeb8','1ee0d5b4d0']\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for j, img_name in enumerate(ids):\n",
    "    q = j+1\n",
    "    img = load_img('./train/images/' + img_name + '.png')\n",
    "    img_mask = load_img('./train/masks/' + img_name + '.png')\n",
    "    \n",
    "    plt.subplot(1,2*(1+len(ids)),q*2-1)\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1,2*(1+len(ids)),q*2)\n",
    "    plt.imshow(img_mask)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Dark patches indicate no salts in the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data and preparation\n",
    "\n",
    "Getting training image ids to load image and mask data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = './train/'   # path to train images and masks\n",
    "path_test = './test/'     # path to test images\n",
    "\n",
    "train_ids = next(os.walk(path_train+\"images\"))[2]\n",
    "test_ids = next(os.walk(path_test+\"images\"))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ids), len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image and mask patches will be resized to 64px by 64px from original 101px by 101px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_height = 64    # new height\n",
    "im_width = 64    # new width\n",
    "im_chan = 1     # number of image channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating empty arrays to hold resized train and test image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((len(train_ids), im_height, im_width, im_chan), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), im_height, im_width, im_chan), dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resizing train images and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = path_train\n",
    "for n, id_ in tqdm_notebook(enumerate(train_ids), total=len(train_ids)):\n",
    "    \n",
    "    img = load_img(path + '/images/' + id_)\n",
    "    x = img_to_array(img)[:,:,1]\n",
    "    x = resize(x, (64, 64, 1), mode='constant', preserve_range=True)\n",
    "    X_train[n] = x\n",
    "    mask = img_to_array(load_img(path + '/masks/' + id_))[:,:,1]\n",
    "    Y_train[n] = resize(mask, (64, 64, 1), mode='constant', preserve_range=True)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quakity check to see if training data looks all right\n",
    "\n",
    "ix = random.randint(0, len(train_ids))\n",
    "plt.imshow(np.dstack((X_train[ix],X_train[ix],X_train[ix])))\n",
    "plt.show()\n",
    "tmp = np.squeeze(Y_train[ix]).astype(np.float32)\n",
    "plt.imshow(np.dstack((tmp,tmp,tmp)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and resizing test image patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty test image arrays\n",
    "\n",
    "X_test = np.zeros((len(test_ids), im_height, im_width, im_chan), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = path_test\n",
    "for n, id_ in tqdm_notebook(enumerate(test_ids), total=len(test_ids)):\n",
    "    \n",
    "    img = load_img(path + '/images/' + id_)\n",
    "    x = img_to_array(img)[:,:,1]\n",
    "    x = resize(x, (64, 64, 1), mode='constant', preserve_range=True)\n",
    "    X_test[n] = x\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training with the U-Net Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![U-Net architecture.png](images/u-net-architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input((im_height, im_width, im_chan))\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (s)\n",
    "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n",
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build U-Net model\n",
    "inputs = Input((im_height, im_width, im_chan))\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "\n",
    "# CONTRASTIVE and ENCODING PART\n",
    "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (s)\n",
    "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n",
    "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n",
    "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n",
    "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\n",
    "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n",
    "\n",
    "# EXPANSIVE and DECODING PART\n",
    "u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n",
    "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n",
    "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n",
    "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n",
    "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n",
    "\n",
    "# OUTPUT LAYER\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the trained model\n",
    "\n",
    "Specify model hyperparameters, and call backs to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "checkpointer = ModelCheckpoint('TGS-salt-model-1.h5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "batch_size = 8\n",
    "validation_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit(X_train, Y_train, validation_split=validation_size, \n",
    "                    batch_size=batch_size, epochs=epochs, callbacks=[earlystopper, checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "Making use of the best saved model to make train, test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on train, val and test\n",
    "model = load_model('TGS-salt-model-1.h5')\n",
    "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.8)], verbose=1)\n",
    "preds_val = model.predict(X_train[int(X_train.shape[0]*0.8):], verbose=1)\n",
    "\n",
    "preds_test = model.predict(X_test, verbose=1)    # test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold predictions\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train_t.shape, preds_val_t.shape, preds_test_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations\n",
    "\n",
    "Visualizing the predicted samples (train and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train samples predicted\n",
    "\n",
    "ix = random.randint(0, len(preds_train_t))\n",
    "imshow(np.squeeze(X_train[ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.show()\n",
    "tmp = np.squeeze(preds_train_t[ix]).astype(np.float32)\n",
    "imshow(np.dstack((tmp,tmp,tmp)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train samples predicted\n",
    "\n",
    "ix = random.randint(0, len(preds_train_t))\n",
    "imshow(np.squeeze(X_train[ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.show()\n",
    "tmp = np.squeeze(preds_train_t[ix]).astype(np.float32)\n",
    "imshow(np.dstack((tmp,tmp,tmp)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train samples predicted\n",
    "\n",
    "ix = random.randint(0, len(preds_train_t))\n",
    "imshow(np.squeeze(X_train[ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.show()\n",
    "tmp = np.squeeze(preds_train_t[ix]).astype(np.float32)\n",
    "imshow(np.dstack((tmp,tmp,tmp)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test samples predicted\n",
    "\n",
    "ix = random.randint(0, len(preds_test_t))\n",
    "imshow(np.squeeze(X_test[ix]))\n",
    "plt.show()\n",
    "tmp = np.squeeze(preds_test_t[ix]).astype(np.float32)\n",
    "imshow(np.dstack((tmp,tmp,tmp)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test samples predicted\n",
    "\n",
    "ix = random.randint(0, len(preds_test_t))\n",
    "imshow(np.squeeze(X_test[ix]))\n",
    "plt.show()\n",
    "tmp = np.squeeze(preds_test_t[ix]).astype(np.float32)\n",
    "imshow(np.dstack((tmp,tmp,tmp)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test samples predicted\n",
    "\n",
    "ix = random.randint(0, len(preds_test_t))\n",
    "imshow(np.squeeze(X_test[ix]))\n",
    "plt.show()\n",
    "tmp = np.squeeze(preds_test_t[ix]).astype(np.float32)\n",
    "imshow(np.dstack((tmp,tmp,tmp)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
